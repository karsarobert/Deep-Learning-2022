{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karsarobert/Deep-Learning-2022/blob/main/10/PTE_DL10_text_generation2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t09eeeR5prIJ"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GCCk8_dHpuNf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovpZyIhNIgoq"
      },
      "source": [
        "# Szöveggenerálás RNN-nel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcD2nPQvPOFM"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/text_generation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwpJ5IffzRG6"
      },
      "source": [
        "Ez a bemutató azt mutatja be, hogyan lehet szöveget generálni egy karakteralapú RNN segítségével. Rejtő Jenő írásaiból álló adatkészlettel fog dolgozni, amely ötlet Andrej Karpathy The Unreasonable Effectiveness of Recurrent Neural Networks című könyvéből származik. Adott egy karaktersorozat ebből az adatból, képezzünk ki egy modellt a sorozat következő karakterének (\"e\") előrejelzésére. A modell ismételt meghívásával hosszabb szövegsorozatok generálhatók.\n",
        "\n",
        "Megjegyzés: Engedélyezze a GPU-gyorsítást a notebook gyorsabb végrehajtásához. A Colab: Futtatási idő > Futtatási idő típusának módosítása > Hardveres gyorsító > GPU.\n",
        "\n",
        "A következő a mintakimenet, amikor az ebben a bemutatóban szereplő modell 30 epochán keresztül képzett, és a \"A\" felszólítással indult:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcygKkEVZBaa"
      },
      "source": [
        "<pre>\n",
        "An saját magaszására társal lett van a pitánsággal, könnyedéseket.\n",
        "A herceg szeme le régen is tűt. Mehes. Fülig Jimmy? Mi ajra, ha Hurcunk Fernántesz! És igen ötök boripán az találgassza, Felség, angol hibetkézik az én nevemben, azt hitte, hogy néhány óráj baj vas, hát de nem hites, előfordul egy erőtel sem mozdult. Pedig a hajón vérn A fiú uralkodásai és lenéssel az illetőkeá.\n",
        "- Hány és GrAndszervez erted?\n",
        "Így öreg Wilson Hutchins (az amerikai fűtő már csak azért sem vonállattag érezte, amelyen a pincér aztán ki történt. Fel tudum. Most már közzem (Övig nem ívás, hanem Jiment furcsa, akkor ja mokdanás, mert a brót és fél személyesen ismerem.\n",
        "- Warins a vőlegverék el - mondja a stamát... Az is a pillanatra! - jegyezte meg közölte?\n",
        "- Ezent lesz a borízsal állt. - Es osztálybal. Öngyen közt kenyeres tudja, ő a próféte megtoválját, így szólt:\n",
        "- Integessen Felség, hogy egy nap alatt sok mindent tett, embere! Hozzt, hogy nem keresem tovább vezeteti Bannera. Tevissza kelé krabitány az á \n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bGsCP9DZFQ5"
      },
      "source": [
        "Bár néhány mondat nyelvtanilag helyes, a legtöbbnek nincs értelme. A modell nem tanulta meg a szavak jelentését, de fontolja meg:\n",
        "\n",
        "* A modell karakteralapú. Amikor a képzés elkezdődött, a modell nem tudta, hogyan kell egy szót leírni, vagy hogy a szavak egyáltalán a szöveg egységei.\n",
        "\n",
        "* Amint azt az alábbiakban bemutatjuk, a modell kis szövegrészleteken (egyenként 100 karakter) tanul, és még mindig képes egy hosszabb, összefüggő szerkezetű szövegsorozatot generálni."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srXC6pLGLwS6"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyKZj3bzf9p"
      },
      "source": [
        "### TensorFlow és más könyvtárak importálása"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHDoRoc5PKWz"
      },
      "source": [
        "### Az adatkészlet letöltése\n",
        "\n",
        "Változtassa meg a következő sort, hogy futtassa ezt a kódot a saját data.c fájlján."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD_55cOxLkAb"
      },
      "outputs": [],
      "source": [
        "#path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjdCjDuSvX_"
      },
      "source": [
        "### Read the data\n",
        "\n",
        "Először nézd meg a szöveget:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aavnuByVymwK",
        "outputId": "426bcff6-8261-4a44-ca8a-2c53afc0c111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 324730 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open('piszkosfred.txt', 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Duhg9NrUymwO",
        "outputId": "56ee352e-8af6-4956-b259-926050af76d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "Rejtő Jenő\r\n",
            "\r\n",
            "Piszkos Fred, a kapitány\r\n",
            "\r\n",
            "ELSŐ FEJEZET\r\n",
            "1\r\n",
            "- Uram! A késemért jöttem!\r\n",
            "- Hol hagyta?\r\n",
            "- Valami matrózban.\r\n",
            "- Milyen kés volt?\r\n",
            "- Acél. Keskeny penge, kissé hajlott. Nem látta?\r\n",
            "- Várjunk... Csak lassan, kérem... Milyen volt a nyele?\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlCgQBRVymwR",
        "outputId": "e76e2a49-8bf0-461f-f096-b845c83bf1ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## A szöveg feldolgozása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjSVAlWzf-N"
      },
      "source": [
        "### A szöveg vektorizálása\n",
        "\n",
        "A képzés előtt a karakterláncokat numerikus ábrázolásra kell konvertálni. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text]) #szöveget pontosabban a karaktereket számokká konvertáljuk"
      ],
      "metadata": {
        "id": "5K4pvyb_3ub3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFXg1IYK4Kcw",
        "outputId": "109620cb-f4fa-4e63-f637-ea3d68b989dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  '\\r':   1,\n",
            "  '\\x1e':   2,\n",
            "  ' ' :   3,\n",
            "  '!' :   4,\n",
            "  '(' :   5,\n",
            "  ')' :   6,\n",
            "  '*' :   7,\n",
            "  ',' :   8,\n",
            "  '-' :   9,\n",
            "  '.' :  10,\n",
            "  '0' :  11,\n",
            "  '1' :  12,\n",
            "  '2' :  13,\n",
            "  '3' :  14,\n",
            "  '4' :  15,\n",
            "  '5' :  16,\n",
            "  '6' :  17,\n",
            "  '7' :  18,\n",
            "  '8' :  19,\n",
            "  ...\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lZx1hAn4QAH",
        "outputId": "ef5d1e99-1249-4c40-fbb7-02080412c62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'\\r\\nRejtő Jenő\\r' ---- characters mapped to int ---- > [ 1  0 40 53 58 68 90  3 33 53 62 90  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbmsf23Bymwe"
      },
      "source": [
        "### A predikciós feladat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wssHQ1oGymwe"
      },
      "source": [
        "Adott egy karakter vagy egy karaktersorozat, mi a legvalószínűbb következő karakter? Ez az a feladat, amire a modellt betanítjuk. A modell bemenete egy karaktersorozat lesz, és a modellt arra képezzük, hogy minden egyes időlépésnél megjósolja a kimenetet - a következő karaktert.\n",
        "\n",
        "Mivel az RNN-ek fenntartanak egy belső állapotot, amely a korábban látott elemektől függ, az adott pillanatig kiszámított összes karaktert figyelembe véve, mi a következő karakter?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### Képzési példák és célok létrehozása\n",
        "\n",
        "Ezután ossza a szöveget példasorozatokra. Minden egyes bemeneti szekvencia a szövegből származó `seq_length` karaktereket tartalmazza.\n",
        "\n",
        "Minden egyes bemeneti szekvenciához a megfelelő célok ugyanolyan hosszúságú szöveget tartalmaznak, kivéve egy karakterrel jobbra eltolva.\n",
        "\n",
        "Tehát a szöveget `seq_length+1` hosszúságú darabokra bontjuk. Tegyük fel például, hogy a `seq_length` 4, és a szövegünk a \"Hello\". A bemeneti szekvencia a \"Hell\", a célszekvencia pedig az \"ello\" lenne.\n",
        "\n",
        "Ehhez először használjuk az `tf.data.Dataset.from_tensor_slices` függvényt, hogy a szövegvektort karakterindexek folyamává alakítsuk."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(10):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0FkvoUp4kGf",
        "outputId": "2f9b641a-0568-4664-c0b9-24fe9297d4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\n",
            "\n",
            "R\n",
            "e\n",
            "j\n",
            "t\n",
            "ő\n",
            " \n",
            "J\n",
            "e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZSYAcQV8OGP"
      },
      "source": [
        "A \"batch\" módszerrel ezeket az egyedi karaktereket könnyen átalakíthatja a kívánt méretű szekvenciákká."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PHW902-4oZt"
      },
      "source": [
        "Könnyebb látni, hogy mit csinál ez, ha a tokeneket visszacsatoljuk karakterláncokká:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpdjRO2CzOfZ",
        "outputId": "ee5fda50-1b31-44c1-d126-0087c1df4efc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'\\r\\nRejtő Jenő\\r\\n\\r\\nPiszkos Fred, a kapitány\\r\\n\\r\\nELSŐ FEJEZET\\r\\n1\\r\\n- Uram! A késemért jöttem!\\r\\n- Hol hagyta'\n",
            "'?\\r\\n- Valami matrózban.\\r\\n- Milyen kés volt?\\r\\n- Acél. Keskeny penge, kissé hajlott. Nem látta?\\r\\n- Várju'\n",
            "'nk... Csak lassan, kérem... Milyen volt a nyele?\\r\\n- Kagyló.\\r\\n- Hány részből?\\r\\n- Egy darabból készült.'\n",
            "'\\r\\n- Akkor nincs baj. Megvan a kés!\\r\\n- Hol?\\r\\n- A hátamban.\\r\\n- Köszönöm...\\r\\n- Kérem... A csapos mesélte'\n",
            "', hogy milyen szép kés van bennem. Egy darab húszcentis kagylóritkaság.\\r\\n- Forduljon meg, kérem, hogy'\n"
          ]
        }
      ],
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbLcIPBj_mWZ"
      },
      "source": [
        "A képzéshez szükséged lesz egy `(bemenet, címke)` párokból álló adathalmazra. Ahol a `bemenet` és \n",
        "`label` szekvenciák. Minden egyes időlépésnél a bemenet az aktuális karakter, a címke pedig a következő karakter. \n",
        "\n",
        "Íme egy függvény, amely bemenetként egy szekvenciát vesz, duplikálja és eltolja azt, hogy minden egyes időlépésnél összehangolja a bemenetet és a címkét:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxbDTJTw5u_P",
        "outputId": "41eb6aa1-16db-4f38-b236-3a2a38ba26e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9iKPXkw5xwa"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNbw-iR0ymwj",
        "outputId": "ad6240f9-8b1c-4001-c974-dabfb681033d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  '\\r\\nRejtő Jenő\\r\\n\\r\\nPiszkos Fred, a kapitány\\r\\n\\r\\nELSŐ FEJEZET\\r\\n1\\r\\n- Uram! A késemért jöttem!\\r\\n- Hol hagyt'\n",
            "Target data: '\\nRejtő Jenő\\r\\n\\r\\nPiszkos Fred, a kapitány\\r\\n\\r\\nELSŐ FEJEZET\\r\\n1\\r\\n- Uram! A késemért jöttem!\\r\\n- Hol hagyta'\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdfPmdqzf-R"
      },
      "source": [
        "### Képzési tételek létrehozása\n",
        "\n",
        "Az `tf.data` segítségével a szöveget kezelhető szekvenciákra osztotta. Mielőtt azonban ezeket az adatokat betáplálnád a modellbe, meg kell keverned az adatokat, és kötegekbe kell csomagolnod őket."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWF7i3kO5exu",
        "outputId": "c9053212-fb5e-4913-ca6a-87d4a74972cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step    0\n",
            "  input: 1 ('\\r')\n",
            "  expected output: 0 ('\\n')\n",
            "Step    1\n",
            "  input: 0 ('\\n')\n",
            "  expected output: 40 ('R')\n",
            "Step    2\n",
            "  input: 40 ('R')\n",
            "  expected output: 53 ('e')\n",
            "Step    3\n",
            "  input: 53 ('e')\n",
            "  expected output: 58 ('j')\n",
            "Step    4\n",
            "  input: 58 ('j')\n",
            "  expected output: 68 ('t')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2pGotuNzf-S",
        "outputId": "8eb1570b-71bd-4df9-e8f9-c0141c79c3b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## A modell megépítése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gPwEjRzf-Z"
      },
      "source": [
        "Ez a szakasz a modellt a `keras.Model` alosztályként definiálja (A részletekért lásd [Új rétegek és modellek létrehozása alosztályozással](https://www.tensorflow.org/guide/keras/custom_layers_and_models)). \n",
        "\n",
        "Ez a modell három réteggel rendelkezik:\n",
        "\n",
        "* `tf.keras.layers.Embedding`: A bemeneti réteg. Egy betanítható keresőtábla, amely minden karakterazonosítót egy `embedding_dim` dimenziójú vektorra képez le;\n",
        "* `tf.keras.layers.GRU`: Egyfajta RNN, amelynek mérete `units=rnn_units` (Itt egy LSTM réteget is használhatsz.)\n",
        "* `tf.keras.layers.Dense`: A kimeneti réteg, `vocab_size` kimenetekkel. A szókészlet minden egyes karakterére egy logaritást ad ki. Ezek az egyes karakterek log-valószínűségét adják meg a modell szerint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "    return model\n",
        "\n",
        "#Ez a kaggleről van"
      ],
      "metadata": {
        "id": "zvD-583W_QnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX58Xj9z47Aw"
      },
      "outputs": [],
      "source": [
        "model = build_model(vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NYIyUAXf8k-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9uGL7MH6Te3",
        "outputId": "d25616fa-c1ee-42c3-b47d-0a29c5ad125d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           24576     \n",
            "                                                                 \n",
            " gru (GRU)                   (64, None, 1024)          3938304   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 96)            98400     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,061,280\n",
            "Trainable params: 4,061,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkA5upJIJ7W7"
      },
      "source": [
        "A modell minden egyes karakterhez megnézi a beágyazást, lefuttatja a GRU-t egy időlépést a beágyazással, és a sűrű réteget alkalmazza a következő karakter logaritmusát előrejelző logaritmusok létrehozására:\n",
        "\n",
        "![A drawing of the data passing through the model](https://github.com/tensorflow/text/blob/master/docs/tutorials/images/text_generation_training.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKbfm04amhXk"
      },
      "source": [
        "Megjegyzés: A képzéshez használhat egy `keras.Sequential` modellt. A későbbi szöveggeneráláshoz az RNN belső állapotát kell majd kezelned. Egyszerűbb előre felvenni az állapot bemeneti és kimeneti beállításait, mint később átrendezni a modell architektúráját. További részletekért lásd a [Keras RNN útmutató](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubPo0_9Prjb"
      },
      "source": [
        "## Próbálja ki a modellt\n",
        "\n",
        "Most futtassa a modellt, hogy lássa, a várakozásoknak megfelelően viselkedik-e.\n",
        "\n",
        "Először ellenőrizze a kimenet alakját:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-_70kKAPrPU",
        "outputId": "5de7704b-fb93-45cf-b1e1-2d5105f0e145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 96) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6NzLBi4VM4o"
      },
      "source": [
        "A fenti példában a bemenet szekvencia hossza \"100\", de a modell bármilyen hosszúságú bemenettel futtatható:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "outputId": "c25abd68-866c-42b0-f9f5-9535e2d5210b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           24576     \n",
            "                                                                 \n",
            " gru (GRU)                   (64, None, 1024)          3938304   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 96)            98400     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,061,280\n",
            "Trainable params: 4,061,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwv0gEkURfx1"
      },
      "source": [
        "Ahhoz, hogy tényleges előrejelzéseket kapjunk a modellből, mintát kell vennünk a kimeneti eloszlásból, hogy megkapjuk a tényleges karakterindexeket. Ezt az eloszlást a karakterszókincs logaritmusai határozzák meg.\n",
        "\n",
        "Megjegyzés: Fontos, hogy ebből az eloszlásból _mintavételezzünk_, mivel az eloszlás _argmax_ értékét véve a modell könnyen hurokba kerülhet.\n",
        "\n",
        "Próbáljuk ki a tétel első példájánál:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM1Vbxs_URw5"
      },
      "source": [
        "Ez minden egyes időlépésnél megadja a következő karakterindex előrejelzését:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqFMUQc_UFgM",
        "outputId": "6074120a-5631-490e-db85-88ef94583694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([75, 92, 61, 73, 10, 37, 62, 59, 50, 95, 26, 88,  8, 82, 61, 90, 27,\n",
              "       12, 74, 29, 79, 72, 51, 38, 83, 23, 17, 33, 72, 52,  6, 21,  2, 22,\n",
              "       79, 46, 27, 50, 17, 20, 62, 42, 65, 30,  1, 49, 67, 78,  2, 41, 95,\n",
              "       15, 60, 84, 94,  2, 25, 36, 68, 21, 70,  3, 68,  5, 17, 94, 86, 30,\n",
              "       93, 32, 43, 94, 52, 87, 80, 75, 85, 53, 86, 80, 80, 93, 95,  4, 87,\n",
              "       13, 71, 52, 18, 45, 85, 52,  2, 28, 77,  9, 40, 86, 70, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLtsP3mUhCG"
      },
      "source": [
        "Dekódolja ezeket, hogy lássa a nem képzett modell által megjósolt szöveget:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWcFwPwLSo05",
        "outputId": "662a3fe8-3e10-4316-cc77-6dba96142449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " '! Tud spanyolul?\\r\\n- Néhány előétel nevét, de azzal úgy-ahogy megértetem magamat.\\r\\n- Hol tanult meg e'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'Áűmy.Nnkb”Cü,ámőD1zFÖxcOé?6Jxd):\\x1e;ÖXDb69nTqG\\rasÓ\\x1eS”4lí“\\x1eBMt:v t(6“öG’IU“dúÚÁóeöÚÚ’”!ú2wd7Wód\\x1eEÍ-Röv:'\n"
          ]
        }
      ],
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## A modell betanítása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCbHQHiaa4Ic"
      },
      "source": [
        "Ezen a ponton a probléma egy szokásos osztályozási problémaként kezelhető. Az előző RNN-állapot és a bemeneti adatok ismeretében ebben az időlépésben meg kell jósolni a következő karakter osztályát."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trpqTWyvk0nr"
      },
      "source": [
        "### Csatoljunk egy optimalizálót és egy veszteségfüggvényt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAjbjY03eiQ4"
      },
      "source": [
        "A szabványos `tf.keras.losses.sparse_categorical_crossentropy` veszteségfüggvény ebben az esetben működik, mivel az előrejelzések utolsó dimenziójára alkalmazzák.\n",
        "\n",
        "Mivel a modelled logitokat ad vissza, be kell állítanod a `from_logits` flaget.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOeWdgxNFDXq"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HrXTACTdzY-",
        "outputId": "7b4e3475-d6a0-4a54-d953-9bb836818678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 96)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.5639973, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkvUIneTFiow"
      },
      "source": [
        "Egy újonnan inicializált modellnek nem szabad túlságosan biztosnak lennie önmagában, a kimeneti logaritmusoknak mind hasonló nagyságúnak kell lenniük. Ennek megerősítésére ellenőrizheti, hogy az átlagos veszteség exponenciálisa megközelítőleg megegyezik-e a szókincs méretével. Egy sokkal nagyobb veszteség azt jelenti, hogy a modell biztos a rossz válaszaiban, és rosszul van inicializálva:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAJfS5YoFiHf",
        "outputId": "8b5e5a7c-8e9e-4523-ae2f-f32c750c0caa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95.96632"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeOXriLcymww"
      },
      "source": [
        "Konfigurálja a képzési eljárást az `tf.keras.Model.compile` módszerrel. Használja az `tf.keras.optimizers.Adam` modellt alapértelmezett argumentumokkal és a veszteségfüggvényt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieSJdchZggUj"
      },
      "source": [
        "### Ellenőrző pontok konfigurálása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6XBUUavgF56"
      },
      "source": [
        "A`tf.keras.callbacks.ModelCheckpoint` használatával biztosíthatja, hogy az ellenőrzési pontok a képzés során mentésre kerüljenek:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6fWTriUZP-n"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ky3F_BhgkTW"
      },
      "source": [
        "### A képzés elvégzése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxdOA-rgyGvs"
      },
      "source": [
        "A képzési idő ésszerűségének megőrzése érdekében használjon 10 epochát a modell képzéséhez. A Colabban a gyorsabb képzés érdekében állítsa a futási időt GPU-ra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK-hmKjYVoll",
        "outputId": "d5e4640a-36c4-4005-f4a1-ddcbf81a7543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "50/50 [==============================] - 5s 55ms/step - loss: 3.7479\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 2.6383\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 2.4248\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 2.3099\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 2.2090\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 2.1113\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 2.0158\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 1.9204\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 1.8293\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 1.7465\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 61ms/step - loss: 1.6728\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 1.6036\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 4s 58ms/step - loss: 1.5406\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 1.4828\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 1.4264\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 1.3720\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 1.3163\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 1.2634\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 1.2094\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 1.1548\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 1.0971\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 1.0374\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.9792\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.9183\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.8581\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.7974\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.7383\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.6778\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.6271\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.5770\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m4PfNfB78ZMv",
        "outputId": "d116faac-d0f8-4e84-822e-c91e26cedaaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_30'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hogy ez az előrejelzési lépés egyszerű legyen, használjon 1 tételméretet.\n",
        "\n",
        "Mivel az RNN állapota időlépésről időlépésre kerül átadásra, a modell csak egy fix kötegméretet fogad el\n",
        "\n",
        "Ha a modellt más batch_mérettel szeretnénk futtatni, újra kell építenünk a modellt, és vissza kell állítanunk a súlyokat az ellenőrzőpontból."
      ],
      "metadata": {
        "id": "_Z1WXoJd8rF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "McHwL99q8apA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Szöveg generálása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIdQ8c8NvMzV"
      },
      "source": [
        "A legegyszerűbben úgy generálhatsz szöveget ezzel a modellel, ha egy ciklusban futtatod, és a végrehajtás során nyomon követed a modell belső állapotát.\n",
        "\n",
        "![A szöveg generálásához a modell kimenete visszakerül a bemenetre](https://github.com/tensorflow/text/blob/master/docs/tutorials/images/text_generation_sampling.png?raw=1)\n",
        "\n",
        "A modell minden egyes meghívásakor átadunk egy szöveget és egy belső állapotot. A modell a következő karakterre vonatkozó előrejelzést és annak új állapotát adja vissza. A szöveggenerálás folytatásához adja vissza a predikciót és az állapotot.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjGz1tDkzf-u"
      },
      "source": [
        "Az alábbiakban egylépéses előrejelzést teszünk:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9yDoa0G3IgQ"
      },
      "source": [
        "Futtassa le egy ciklusban, hogy létrehozzon egy szöveget. Ha megnézzük a generált szöveget, láthatjuk, hogy a modell tudja, mikor kell nagybetűvel írni, bekezdéseket alkotni, és Rejtő-szerű írásszókincset utánoz. A kevés gyakorló epocha miatt még nem tanulta meg, hogy összefüggő mondatokat alkosson.\n",
        "\n",
        "A kezdő karakterlánc kiválasztásával, az RNN állapotának inicializálásával és a létrehozandó karakterek számának beállításával kezdődik.\n",
        "\n",
        "Megszerzi a következő karakter előrejelzési eloszlását a kezdő karakterlánc és az RNN állapot felhasználásával.\n",
        "\n",
        "Ezután egy kategorikus eloszlás segítségével kiszámítja a megjósolt karakter indexét. Használjuk ezt a megjósolt karaktert a modell következő bemeneteként.\n",
        "\n",
        "A modell által visszaküldött RNN-állapotot visszatápláljuk a modellbe, így az most már több kontextussal rendelkezik, nem csak egy karakterrel. A következő karakter előrejelzése után a módosított RNN-állapotokat ismét visszatápláljuk a modellbe, így az tanul, mivel több kontextust kap a korábban megjósolt karakterekből.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):  \n",
        "  \n",
        "    num_generate = 1000\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "   \n",
        "    text_generated = []\n",
        "\n",
        "    temperature = 1.0\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0) #1-es dimenziókat eltávolítja\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "Q9-KvnSE0q0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"A\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0s1AX0C0sOQ",
        "outputId": "f178d252-097a-4f59-ead7-f517805d6540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALHARHATIHATIN\r\n",
            "TALOSKKÖLJEZET\r\n",
            "AZ IGAZGATÓSÁG\r\n",
            "Mint Mivan az indulat, és skédül já. Azt viszont az “mesét. A Radzeer cirkától és mint a beszélőret. Nevet uniforgó...”\r\n",
            "- Milyen a kikötőben megvető a komlátán átközdön átnál, és megnézem az illetőt! Igaza volt. (Folytatása tette, ha az ember nőtl ülyem az.\r\n",
            "- Szerszám, de arszűlöncön okmásokkol csavargó jön a dolgot. Azóta elyikkedd os királynak.\r\n",
            "Ahotal becsap el banuldalt, hogy nagyon jó dolgom vona.\r\n",
            "- Azt hiszem -, de az sem baj zavatolni kezdett.\r\n",
            "- Fogja meg! Most már? Asz asztalon ült, a szívó lenne a tarkát.\r\n",
            "- Néhány imbolygó. Ítt az első merült és visszatért hiszhetvenöt dollár.\r\n",
            "- Azért jött?\r\n",
            "- Ne kérdezzen, hanem zseniáli Tr.\r\n",
            "Ildogozú úgy testhet meg egy parikát, amelyen ezdélcsendben nincs is... Mit csinál itt sorr Felség! nekem kevetett.\r\n",
            "- Miért nevetséghez formasing adott gépies előszédnek. Elegusítom ebből az alvilágot mert volt az első Füsig, hogy egyint sohasem kopogott a mentőcsónakokat. 3\r\n",
            "Csak ez igy igen szenyori\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM2Uma_-yVIq"
      },
      "source": [
        "A legegyszerűbb dolog, amit tehetsz az eredmények javítása érdekében, hogy hosszabb ideig edzed (próbáld ki az `EPOCHS = 30`).\n",
        "\n",
        "Kísérletezhet más kezdő stringgel is, megpróbálhat egy másik RNN réteget hozzáadni a modell pontosságának javítása érdekében, vagy beállíthatja a hőmérséklet paramétert, hogy több vagy kevesebb véletlenszerű előrejelzést generáljon."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =[]\n",
        "input_eval = [char2idx[s] for s in 'A']\n",
        "input_eval = tf.expand_dims(input_eval, 0)\n",
        "predictions = model(input_eval)"
      ],
      "metadata": {
        "id": "1rnHlQK5-K_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = tf.squeeze(predictions, 0)"
      ],
      "metadata": {
        "id": "I-mOOf8j-PaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJt1WucL-kxn",
        "outputId": "f68d51f7-a051-48d8-b8d6-6d44bb9c70f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.1923974>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()"
      ],
      "metadata": {
        "id": "jBoIIKxr-tME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_eval = tf.expand_dims([predicted_id], 0)\n",
        "text.append(idx2char[predicted_id])"
      ],
      "metadata": {
        "id": "hHpwgt9j_2hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_CfM2ZU0AFkM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}