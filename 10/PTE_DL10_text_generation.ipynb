{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karsarobert/Deep-Learning-2022/blob/main/10/PTE_DL10_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t09eeeR5prIJ"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GCCk8_dHpuNf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovpZyIhNIgoq"
      },
      "source": [
        "# Szöveggenerálás RNN-nel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcD2nPQvPOFM"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/text_generation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwpJ5IffzRG6"
      },
      "source": [
        "Ez a bemutató azt mutatja be, hogyan lehet szöveget generálni egy karakteralapú RNN segítségével. Rejtő Jenő írásaiból álló adatkészlettel fog dolgozni, amely ötlet Andrej Karpathy The Unreasonable Effectiveness of Recurrent Neural Networks című könyvéből származik. Adott egy karaktersorozat ebből az adatból, képezzünk ki egy modellt a sorozat következő karakterének (\"e\") előrejelzésére. A modell ismételt meghívásával hosszabb szövegsorozatok generálhatók.\n",
        "\n",
        "Megjegyzés: Engedélyezze a GPU-gyorsítást a notebook gyorsabb végrehajtásához. A Colab: Futtatási idő > Futtatási idő típusának módosítása > Hardveres gyorsító > GPU.\n",
        "\n",
        "Ez a bemutató tf.keras és eager execution használatával megvalósított futtatható kódot tartalmaz. A következő a mintakimenet, amikor az ebben a bemutatóban szereplő modell 30 epochán keresztül képzett, és a \"A\" felszólítással indult:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcygKkEVZBaa"
      },
      "source": [
        "<pre>\n",
        "An saját magaszására társal lett van a pitánsággal, könnyedéseket.\n",
        "A herceg szeme le régen is tűt. Mehes. Fülig Jimmy? Mi ajra, ha Hurcunk Fernántesz! És igen ötök boripán az találgassza, Felség, angol hibetkézik az én nevemben, azt hitte, hogy néhány óráj baj vas, hát de nem hites, előfordul egy erőtel sem mozdult. Pedig a hajón vérn A fiú uralkodásai és lenéssel az illetőkeá.\n",
        "- Hány és GrAndszervez erted?\n",
        "Így öreg Wilson Hutchins (az amerikai fűtő már csak azért sem vonállattag érezte, amelyen a pincér aztán ki történt. Fel tudum. Most már közzem (Övig nem ívás, hanem Jiment furcsa, akkor ja mokdanás, mert a brót és fél személyesen ismerem.\n",
        "- Warins a vőlegverék el - mondja a stamát... Az is a pillanatra! - jegyezte meg közölte?\n",
        "- Ezent lesz a borízsal állt. - Es osztálybal. Öngyen közt kenyeres tudja, ő a próféte megtoválját, így szólt:\n",
        "- Integessen Felség, hogy egy nap alatt sok mindent tett, embere! Hozzt, hogy nem keresem tovább vezeteti Bannera. Tevissza kelé krabitány az á \n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bGsCP9DZFQ5"
      },
      "source": [
        "Bár néhány mondat nyelvtanilag helyes, a legtöbbnek nincs értelme. A modell nem tanulta meg a szavak jelentését, de fontolja meg:\n",
        "\n",
        "* A modell karakteralapú. Amikor a képzés elkezdődött, a modell nem tudta, hogyan kell egy szót leírni, vagy hogy a szavak egyáltalán a szöveg egységei.\n",
        "\n",
        "* Amint azt az alábbiakban bemutatjuk, a modell kis szövegrészleteken (egyenként 100 karakter) tanul, és még mindig képes egy hosszabb, összefüggő szerkezetű szövegsorozatot generálni."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srXC6pLGLwS6"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyKZj3bzf9p"
      },
      "source": [
        "### TensorFlow és más könyvtárak importálása"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHDoRoc5PKWz"
      },
      "source": [
        "### Az adatkészlet letöltése\n",
        "\n",
        "Változtassa meg a következő sort, hogy futtassa ezt a kódot a saját data.c fájlján."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD_55cOxLkAb"
      },
      "outputs": [],
      "source": [
        "#path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjdCjDuSvX_"
      },
      "source": [
        "### Read the data\n",
        "\n",
        "Először nézd meg a szöveget:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aavnuByVymwK",
        "outputId": "97ba268c-9377-44e6-9f1a-3f9580dd8a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 324730 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open('piszkosfred.txt', 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Duhg9NrUymwO",
        "outputId": "24e542a0-321e-4716-b92b-281e3a725e55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "Rejtő Jenő\r\n",
            "\r\n",
            "Piszkos Fred, a kapitány\r\n",
            "\r\n",
            "ELSŐ FEJEZET\r\n",
            "1\r\n",
            "- Uram! A késemért jöttem!\r\n",
            "- Hol hagyta?\r\n",
            "- Valami matrózban.\r\n",
            "- Milyen kés volt?\r\n",
            "- Acél. Keskeny penge, kissé hajlott. Nem látta?\r\n",
            "- Várjunk... Csak lassan, kérem... Milyen volt a nyele?\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlCgQBRVymwR",
        "outputId": "dd95a74f-643e-43fa-8005-1ffe838796a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## A szöveg feldolgozása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjSVAlWzf-N"
      },
      "source": [
        "### A szöveg vektorizálása\n",
        "\n",
        "A képzés előtt a karakterláncokat numerikus ábrázolásra kell konvertálni. \n",
        "\n",
        "Az `tf.keras.layers.StringLookup` réteg képes minden karaktert numerikus azonosítóvá alakítani. Csak előbb tokenekre kell bontani a szöveget."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a86OoYtO01go",
        "outputId": "e094573c-7528-4eba-b431-c301c431aaea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'l', b'm', b'a'], [b's', b'z', b'i', b'l', b'v', b'a']]>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "example_texts = ['alma', 'szilva']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s4f1q3iqY8f"
      },
      "source": [
        "Most hozzuk létre az `tf.keras.layers.StringLookup` réteget:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GMlCe3qzaL9"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmX_jbgQqfOi"
      },
      "source": [
        "A tokenekről karakterazonosítókra konvertál:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLv5Q_2TC2pc",
        "outputId": "3ed1012f-5058-4e4e-d044-6afb3130e0b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[50, 61, 62, 50], [68, 75, 58, 61, 71, 50]]>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZfqhkYCymwX"
      },
      "source": [
        "Mivel ennek a bemutatónak az a célja, hogy szöveget generáljon, fontos lesz ezt a reprezentációt megfordítani, és ember által olvasható karakterláncokat visszanyerni belőle. Ehhez használhatjuk az `tf.keras.layers.StringLookup(...., invert=True)` parancsot.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uenivzwqsDhp"
      },
      "source": [
        "Megjegyzés: Itt a `sorted(set(text))` segítségével generált eredeti szókincs átadása helyett használjuk az `tf.keras.layers.StringLookup` réteg `get_vocabulary()` módszerét, hogy a `[UNK]` tokenek ugyanúgy legyenek beállítva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd2m3mqkDjRj"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqTDDxS-s-H8"
      },
      "source": [
        "Ez a réteg visszanyeri a karaktereket az azonosítók vektoraiból, és egy `tf.RaggedTensor` karakterek formájában adja vissza őket:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2GCh0ySD44s",
        "outputId": "62bf806a-b6b1-4bd0-822a-91e72a03143f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'l', b'm', b'a'], [b's', b'z', b'i', b'l', b'v', b'a']]>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FeW5gqutT3o"
      },
      "source": [
        "Az `tf.strings.reduce_join` segítségével a karaktereket visszaillesztheted a karakterláncokba. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxYI-PeltqKP",
        "outputId": "a43a1811-5405-4e93-da61-bf7fc81e4a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'alma', b'szilva'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5apvBDn9Ind"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbmsf23Bymwe"
      },
      "source": [
        "### A predikciós feladat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wssHQ1oGymwe"
      },
      "source": [
        "Adott egy karakter vagy egy karaktersorozat, mi a legvalószínűbb következő karakter? Ez az a feladat, amire a modellt betanítjuk. A modell bemenete egy karaktersorozat lesz, és a modellt arra képezzük, hogy minden egyes időlépésnél megjósolja a kimenetet - a következő karaktert.\n",
        "\n",
        "Mivel az RNN-ek fenntartanak egy belső állapotot, amely a korábban látott elemektől függ, az adott pillanatig kiszámított összes karaktert figyelembe véve, mi a következő karakter?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### Képzési példák és célok létrehozása\n",
        "\n",
        "Ezután ossza a szöveget példasorozatokra. Minden egyes bemeneti szekvencia a szövegből származó `seq_length` karaktereket tartalmazza.\n",
        "\n",
        "Minden egyes bemeneti szekvenciához a megfelelő célok ugyanolyan hosszúságú szöveget tartalmaznak, kivéve egy karakterrel jobbra eltolva.\n",
        "\n",
        "Tehát a szöveget `seq_length+1` hosszúságú darabokra bontjuk. Tegyük fel például, hogy a `seq_length` 4, és a szövegünk a \"Hello\". A bemeneti szekvencia a \"Hell\", a célszekvencia pedig az \"ello\" lenne.\n",
        "\n",
        "Ehhez először használjuk az `tf.data.Dataset.from_tensor_slices` függvényt, hogy a szövegvektort karakterindexek folyamává alakítsuk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UopbsKi88tm5",
        "outputId": "c47b5ae5-d3cf-4186-e83a-5289dba40f13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(324730,), dtype=int64, numpy=array([ 2,  1, 41, ...,  1,  2,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmxrYDCTy-eL"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUO0NKSces1o",
        "outputId": "c239c92c-6b81-417d-a9d1-45180004d647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjH5v45-yqqH",
        "outputId": "aabaa482-aedc-4424-cc78-08962bd0460d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\n",
            "\n",
            "R\n",
            "e\n",
            "j\n",
            "t\n",
            "ő\n",
            " \n",
            "J\n",
            "e\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-G2oaTxy6km"
      },
      "outputs": [],
      "source": [
        "seq_length = 100\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZSYAcQV8OGP"
      },
      "source": [
        "A \"batch\" módszerrel ezeket az egyedi karaktereket könnyen átalakíthatja a kívánt méretű szekvenciákká."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpdjRO2CzOfZ",
        "outputId": "72034095-ec70-41cf-ae5c-ed904a6ee54d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\r' b'\\n' b'R' b'e' b'j' b't' b'\\xc5\\x91' b' ' b'J' b'e' b'n'\n",
            " b'\\xc5\\x91' b'\\r' b'\\n' b'\\r' b'\\n' b'P' b'i' b's' b'z' b'k' b'o' b's'\n",
            " b' ' b'F' b'r' b'e' b'd' b',' b' ' b'a' b' ' b'k' b'a' b'p' b'i' b't'\n",
            " b'\\xc3\\xa1' b'n' b'y' b'\\r' b'\\n' b'\\r' b'\\n' b'E' b'L' b'S' b'\\xc5\\x90'\n",
            " b' ' b'F' b'E' b'J' b'E' b'Z' b'E' b'T' b'\\r' b'\\n' b'1' b'\\r' b'\\n' b'-'\n",
            " b' ' b'U' b'r' b'a' b'm' b'!' b' ' b'A' b' ' b'k' b'\\xc3\\xa9' b's' b'e'\n",
            " b'm' b'\\xc3\\xa9' b'r' b't' b' ' b'j' b'\\xc3\\xb6' b't' b't' b'e' b'm' b'!'\n",
            " b'\\r' b'\\n' b'-' b' ' b'H' b'o' b'l' b' ' b'h' b'a' b'g' b'y' b't' b'a'], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PHW902-4oZt"
      },
      "source": [
        "Könnyebb látni, hogy mit csinál ez, ha a tokeneket visszacsatoljuk karakterláncokká:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO32cMWu4a06",
        "outputId": "ed1075f3-852d-46e6-f4b6-156af1c0d0f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\r\\nRejt\\xc5\\x91 Jen\\xc5\\x91\\r\\n\\r\\nPiszkos Fred, a kapit\\xc3\\xa1ny\\r\\n\\r\\nELS\\xc5\\x90 FEJEZET\\r\\n1\\r\\n- Uram! A k\\xc3\\xa9sem\\xc3\\xa9rt j\\xc3\\xb6ttem!\\r\\n- Hol hagyta'\n",
            "b'?\\r\\n- Valami matr\\xc3\\xb3zban.\\r\\n- Milyen k\\xc3\\xa9s volt?\\r\\n- Ac\\xc3\\xa9l. Keskeny penge, kiss\\xc3\\xa9 hajlott. Nem l\\xc3\\xa1tta?\\r\\n- V\\xc3\\xa1rju'\n",
            "b'nk... Csak lassan, k\\xc3\\xa9rem... Milyen volt a nyele?\\r\\n- Kagyl\\xc3\\xb3.\\r\\n- H\\xc3\\xa1ny r\\xc3\\xa9szb\\xc5\\x91l?\\r\\n- Egy darabb\\xc3\\xb3l k\\xc3\\xa9sz\\xc3\\xbclt.'\n",
            "b'\\r\\n- Akkor nincs baj. Megvan a k\\xc3\\xa9s!\\r\\n- Hol?\\r\\n- A h\\xc3\\xa1tamban.\\r\\n- K\\xc3\\xb6sz\\xc3\\xb6n\\xc3\\xb6m...\\r\\n- K\\xc3\\xa9rem... A csapos mes\\xc3\\xa9lte'\n",
            "b', hogy milyen sz\\xc3\\xa9p k\\xc3\\xa9s van bennem. Egy darab h\\xc3\\xbaszcentis kagyl\\xc3\\xb3ritkas\\xc3\\xa1g.\\r\\n- Forduljon meg, k\\xc3\\xa9rem, hogy'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbLcIPBj_mWZ"
      },
      "source": [
        "A képzéshez szükséged lesz egy `(bemenet, címke)` párokból álló adathalmazra. Ahol a `bemenet` és \n",
        "`label` szekvenciák. Minden egyes időlépésnél a bemenet az aktuális karakter, a címke pedig a következő karakter. \n",
        "\n",
        "Íme egy függvény, amely bemenetként egy szekvenciát vesz, duplikálja és eltolja azt, hogy minden egyes időlépésnél összehangolja a bemenetet és a címkét:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxbDTJTw5u_P",
        "outputId": "ac033c5e-9ba3-4b5f-f7d9-2b9a244d9ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9iKPXkw5xwa"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNbw-iR0ymwj",
        "outputId": "7709dfa8-d500-4b43-a77e-6f0ba4d7f875",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'\\r\\nRejt\\xc5\\x91 Jen\\xc5\\x91\\r\\n\\r\\nPiszkos Fred, a kapit\\xc3\\xa1ny\\r\\n\\r\\nELS\\xc5\\x90 FEJEZET\\r\\n1\\r\\n- Uram! A k\\xc3\\xa9sem\\xc3\\xa9rt j\\xc3\\xb6ttem!\\r\\n- Hol hagyt'\n",
            "Target: b'\\nRejt\\xc5\\x91 Jen\\xc5\\x91\\r\\n\\r\\nPiszkos Fred, a kapit\\xc3\\xa1ny\\r\\n\\r\\nELS\\xc5\\x90 FEJEZET\\r\\n1\\r\\n- Uram! A k\\xc3\\xa9sem\\xc3\\xa9rt j\\xc3\\xb6ttem!\\r\\n- Hol hagyta'\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdfPmdqzf-R"
      },
      "source": [
        "### Képzési tételek létrehozása\n",
        "\n",
        "Az `tf.data` segítségével a szöveget kezelhető szekvenciákra osztotta. Mielőtt azonban ezeket az adatokat betáplálnád a modellbe, meg kell keverned az adatokat, és kötegekbe kell csomagolnod őket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2pGotuNzf-S",
        "outputId": "04feb976-f8cc-47fd-c66f-aed87cd2262a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## A modell megépítése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gPwEjRzf-Z"
      },
      "source": [
        "Ez a szakasz a modellt a `keras.Model` alosztályként definiálja (A részletekért lásd [Új rétegek és modellek létrehozása alosztályozással](https://www.tensorflow.org/guide/keras/custom_layers_and_models)). \n",
        "\n",
        "Ez a modell három réteggel rendelkezik:\n",
        "\n",
        "* `tf.keras.layers.Embedding`: A bemeneti réteg. Egy betanítható keresőtábla, amely minden karakterazonosítót egy `embedding_dim` dimenziójú vektorra képez le;\n",
        "* `tf.keras.layers.GRU`: Egyfajta RNN, amelynek mérete `units=rnn_units` (Itt egy LSTM réteget is használhatsz.)\n",
        "* `tf.keras.layers.Dense`: A kimeneti réteg, `vocab_size` kimenetekkel. A szókészlet minden egyes karakterére egy logaritást ad ki. Ezek az egyes karakterek log-valószínűségét adják meg a modell szerint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj8HQ2w8z4iO"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "    return model\n",
        "\n",
        "#Ez a kaggleről van"
      ],
      "metadata": {
        "id": "zvD-583W_QnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX58Xj9z47Aw"
      },
      "outputs": [],
      "source": [
        "'''model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)'''\n",
        "\n",
        "model = build_model(vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NYIyUAXf8k-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkA5upJIJ7W7"
      },
      "source": [
        "A modell minden egyes karakterhez megnézi a beágyazást, lefuttatja a GRU-t egy időlépést a beágyazással, és a sűrű réteget alkalmazza a következő karakter logaritmusát előrejelző logaritmusok létrehozására:\n",
        "\n",
        "![A drawing of the data passing through the model](https://github.com/tensorflow/text/blob/master/docs/tutorials/images/text_generation_training.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKbfm04amhXk"
      },
      "source": [
        "Megjegyzés: A képzéshez használhat egy `keras.Sequential` modellt. A későbbi szöveggeneráláshoz az RNN belső állapotát kell majd kezelned. Egyszerűbb előre felvenni az állapot bemeneti és kimeneti beállításait, mint később átrendezni a modell architektúráját. További részletekért lásd a [Keras RNN útmutató](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubPo0_9Prjb"
      },
      "source": [
        "## Próbálja ki a modellt\n",
        "\n",
        "Most futtassa a modellt, hogy lássa, a várakozásoknak megfelelően viselkedik-e.\n",
        "\n",
        "Először ellenőrizze a kimenet alakját:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-_70kKAPrPU",
        "outputId": "c01488f3-c87e-4a03-d3e4-0dffe045d1b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 97) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6NzLBi4VM4o"
      },
      "source": [
        "A fenti példában a bemenet szekvencia hossza \"100\", de a modell bármilyen hosszúságú bemenettel futtatható:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "outputId": "6b31d994-8ddb-4266-d6bb-3cc828e32f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (64, None, 256)           24832     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (64, None, 1024)          3938304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (64, None, 97)            99425     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,561\n",
            "Trainable params: 4,062,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwv0gEkURfx1"
      },
      "source": [
        "Ahhoz, hogy tényleges előrejelzéseket kapjunk a modellből, mintát kell vennünk a kimeneti eloszlásból, hogy megkapjuk a tényleges karakterindexeket. Ezt az eloszlást a karakterszókincs logaritmusai határozzák meg.\n",
        "\n",
        "Megjegyzés: Fontos, hogy ebből az eloszlásból _mintavételezzünk_, mivel az eloszlás _argmax_ értékét véve a modell könnyen hurokba kerülhet.\n",
        "\n",
        "Próbáljuk ki a tétel első példájánál:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM1Vbxs_URw5"
      },
      "source": [
        "Ez minden egyes időlépésnél megadja a következő karakterindex előrejelzését:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqFMUQc_UFgM",
        "outputId": "1a91a647-6469-4a8a-e730-bb30171af337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14,  2,  2, 80, 76, 57, 77, 78, 39, 69, 29, 95, 27, 71, 83, 81, 81,\n",
              "       82, 34, 26, 33, 10, 62, 54, 62, 58, 71, 31, 46, 31, 20, 65,  7, 78,\n",
              "       63, 15, 78, 67, 41, 72, 54, 56, 54, 28, 93, 19, 76, 78, 34, 29, 65,\n",
              "       84, 74, 87,  6, 27, 41, 76, 17, 67, 62, 45, 73, 22, 83, 30, 78, 88,\n",
              "       88, 68, 69, 58, 19, 33,  1, 50, 64, 81, 14, 30,  2, 26, 96, 60, 72,\n",
              "       66, 64,  5, 32, 50, 96, 55, 89, 18, 45, 81, 32, 91, 41, 89])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLtsP3mUhCG"
      },
      "source": [
        "Dekódolja ezeket, hogy lássa a nem képzett modell által megjósolt szöveget:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWcFwPwLSo05",
        "outputId": "21982672-3b74-4edc-aa5a-25b9c3bea79f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'.\\r\\nMr. Irving mindent feljegyzett egy piros noteszbe, \\xc3\\xa9s elhat\\xc3\\xa1rozta, hogy meg is tanulja.\\r\\n- A Vel\\xc5\\x91'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'2\\r\\r\\xc3\\x96\\xc3\\x81h\\xc3\\x89\\xc3\\x8dOtE\\xe2\\x80\\x9cCv\\xc3\\xa1\\xc3\\x9a\\xc3\\x9a\\xc3\\x9cJBI-memivGWG8p)\\xc3\\x8dn3\\xc3\\x8drRwegeD\\xc5\\xb17\\xc3\\x81\\xc3\\x8dJEp\\xc3\\xa9y\\xc3\\xb6(CR\\xc3\\x815rmVx:\\xc3\\xa1F\\xc3\\x8d\\xc3\\xba\\xc3\\xbasti7I\\nao\\xc3\\x9a2F\\rB\\xe2\\x80\\x9dkwqo!Ha\\xe2\\x80\\x9df\\xc3\\xbc6V\\xc3\\x9aH\\xc5\\x91R\\xc3\\xbc'\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## A modell betanítása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCbHQHiaa4Ic"
      },
      "source": [
        "Ezen a ponton a probléma egy szokásos osztályozási problémaként kezelhető. Az előző RNN-állapot és a bemeneti adatok ismeretében ebben az időlépésben meg kell jósolni a következő karakter osztályát."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trpqTWyvk0nr"
      },
      "source": [
        "### Csatoljunk egy optimalizálót és egy veszteségfüggvényt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAjbjY03eiQ4"
      },
      "source": [
        "A szabványos `tf.keras.losses.sparse_categorical_crossentropy` veszteségfüggvény ebben az esetben működik, mivel az előrejelzések utolsó dimenziójára alkalmazzák.\n",
        "\n",
        "Mivel a modelled logitokat ad vissza, be kell állítanod a `from_logits` flaget.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOeWdgxNFDXq"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HrXTACTdzY-",
        "outputId": "202d31ab-3bea-4bc6-80b0-a389a2d83669",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 97)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.574665, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkvUIneTFiow"
      },
      "source": [
        "Egy újonnan inicializált modellnek nem szabad túlságosan biztosnak lennie önmagában, a kimeneti logaritmusoknak mind hasonló nagyságúnak kell lenniük. Ennek megerősítésére ellenőrizheti, hogy az átlagos veszteség exponenciálisa megközelítőleg megegyezik-e a szókincs méretével. Egy sokkal nagyobb veszteség azt jelenti, hogy a modell biztos a rossz válaszaiban, és rosszul van inicializálva:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAJfS5YoFiHf",
        "outputId": "4159db0d-db63-47a2-fc18-5b2d48d03f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.995544"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeOXriLcymww"
      },
      "source": [
        "Konfigurálja a képzési eljárást az `tf.keras.Model.compile` módszerrel. Használja az `tf.keras.optimizers.Adam` modellt alapértelmezett argumentumokkal és a veszteségfüggvényt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieSJdchZggUj"
      },
      "source": [
        "### Ellenőrző pontok konfigurálása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6XBUUavgF56"
      },
      "source": [
        "A`tf.keras.callbacks.ModelCheckpoint` használatával biztosíthatja, hogy az ellenőrzési pontok a képzés során mentésre kerüljenek:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6fWTriUZP-n"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ky3F_BhgkTW"
      },
      "source": [
        "### A képzés elvégzése"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxdOA-rgyGvs"
      },
      "source": [
        "A képzési idő ésszerűségének megőrzése érdekében használjon 10 epochát a modell képzéséhez. A Colabban a gyorsabb képzés érdekében állítsa a futási időt GPU-ra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK-hmKjYVoll",
        "outputId": "f626d299-18ad-48fa-c1c0-bf34ba45c2a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "50/50 [==============================] - 5s 53ms/step - loss: 3.7242\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 2.6969\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 2.4494\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 2.3331\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 2.2335\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 2.1369\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 2.0405\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 1.9473\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 1.8551\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 1.7730\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 1.6937\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 1.6196\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 1.5521\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 1.4865\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 1.4236\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 1.3582\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 1.2977\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 1.2344\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 1.1673\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 1.0975\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 1.0246\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 0.9486\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 4s 55ms/step - loss: 0.8693\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.7898\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.7075\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.6261\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.5470\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 0.4709\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.4031\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.3429\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Szöveg generálása"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIdQ8c8NvMzV"
      },
      "source": [
        "A legegyszerűbben úgy generálhatsz szöveget ezzel a modellel, ha egy ciklusban futtatod, és a végrehajtás során nyomon követed a modell belső állapotát.\n",
        "\n",
        "![A szöveg generálásához a modell kimenete visszakerül a bemenetre](https://github.com/tensorflow/text/blob/master/docs/tutorials/images/text_generation_sampling.png?raw=1)\n",
        "\n",
        "A modell minden egyes meghívásakor átadunk egy szöveget és egy belső állapotot. A modell a következő karakterre vonatkozó előrejelzést és annak új állapotát adja vissza. A szöveggenerálás folytatásához adja vissza a predikciót és az állapotot.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjGz1tDkzf-u"
      },
      "source": [
        "Az alábbiakban egylépéses előrejelzést teszünk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSBU1tHmlUSs"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqMOuDutnOxK"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9yDoa0G3IgQ"
      },
      "source": [
        "Futtassa le egy ciklusban, hogy létrehozzon egy szöveget. Ha megnézzük a generált szöveget, láthatjuk, hogy a modell tudja, mikor kell nagybetűvel írni, bekezdéseket alkotni, és Rejtő-szerű írásszókincset utánoz. A kevés gyakorló epocha miatt még nem tanulta meg, hogy összefüggő mondatokat alkosson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST7PSyk9t1mT",
        "outputId": "1f24a5f1-0d33-44d1-ae4f-4876e5f03417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An saját magaszására társal lett van a pitánsággal, könnyedéseket.\r\n",
            "A herceg szeme le régen is tűt. Mehes. Fülig Jimmy? Mi ajra, ha Hurcunk Fernántesz! És igen ötök boripán az találgassza, Felség, angol hibetkézik az én nevemben, azt hitte, hogy néhány óráj baj vas, hát de nem hites, előfordul egy erőtel sem mozdult. Pedig a hajón vérn A fiú uralkodásai és lenéssel az illetőkeá.\r\n",
            "- Hány és GrAndszervez erted?\r\n",
            "Így öreg Wilson Hutchins (az amerikai fűtő már csak azért sem vonállattag érezte, amelyen a pincér aztán ki történt. Fel tudum. Most már közzem (Övig nem ívás, hanem Jiment furcsa, akkor ja mokdanás, mert a brót és fél személyesen ismerem.\r\n",
            "- Warins a vőlegverék el - mondja a stamát... Az is a pillanatra! - jegyezte meg közölte?\r\n",
            "- Ezent lesz a borízsal állt. - Es osztálybal. Öngyen közt kenyeres tudja, ő a próféte megtoválját, így szólt:\r\n",
            "- Integessen Felség, hogy egy nap alatt sok mindent tett, embere! Hozzt, hogy nem keresem tovább vezeteti Bannera. Tevissza kelé krabitány az á \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.307584762573242\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['A'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)"
      ],
      "metadata": {
        "id": "hoMVaZRS1yeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):  \n",
        "  \n",
        "    num_generate = 1000\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "   \n",
        "    text_generated = []\n",
        "\n",
        "    temperature = 1.0\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "Q9-KvnSE0q0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model, start_string=u\"A\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "G0s1AX0C0sOQ",
        "outputId": "c345622b-c58e-46fc-8041-c5e332d0d2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-be83e0747b28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu\"A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-00ef3387f379>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, start_string)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\u001b[0m\u001b[1;32m    265\u001b[0m                              \u001b[0;34m'incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                              \u001b[0;34mf'expected shape={spec.shape}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"sequential\" (type Sequential).\n\nInput 0 of layer \"gru_1\" is incompatible with the layer: expected shape=(64, None, 256), found shape=(1, 1, 256)\n\nCall arguments received by layer \"sequential\" (type Sequential):\n  • inputs=tf.Tensor(shape=(1, 1), dtype=int32)\n  • training=None\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM2Uma_-yVIq"
      },
      "source": [
        "A legegyszerűbb dolog, amit tehetsz az eredmények javítása érdekében, hogy hosszabb ideig edzed (próbáld ki az `EPOCHS = 30`).\n",
        "\n",
        "Kísérletezhet más kezdő stringgel is, megpróbálhat egy másik RNN réteget hozzáadni a modell pontosságának javítása érdekében, vagy beállíthatja a hőmérséklet paramétert, hogy több vagy kevesebb véletlenszerű előrejelzést generáljon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlUQzwu6EXam"
      },
      "source": [
        "## Export the generator\n",
        "\n",
        "This single-step model can easily be [saved and restored](https://www.tensorflow.org/guide/saved_model), allowing you to use it anywhere a `tf.saved_model` is accepted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Grk32H_CzsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f03fd4-639d-4094-90c9-60b6343a703a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f2bbc4a7c50>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}